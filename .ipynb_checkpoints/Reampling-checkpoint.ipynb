{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automated-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cvxpy as cp\n",
    "import scipy.stats as st\n",
    "from scipy.stats import uniform,norm\n",
    "from utils.metropolishastings import MetropolisHastings\n",
    "from utils.state import State\n",
    "from utils.drawing import discrete_inverse_trans, \\\n",
    "    transform_into_marginals_clean, DFconditional, draw_from_marginals\n",
    "from utils.statistical_assessments import stats_assessment\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import matplotlib\n",
    "import copy\n",
    "import warnings\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import tikzplotlib\n",
    "from datetime import datetime\n",
    "from matplotlib.cm import get_cmap\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "herbal-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-capitol",
   "metadata": {},
   "source": [
    "### Identifying the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overhead-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_2010_2015 = pd.read_csv(\"results/proj2010_2015/synthetic_2010_2015_99.csv\") #results of projection from 2010 to 2015\n",
    "real_data_2015 = pd.read_csv(\"results/merged/bs_1_hh.csv\") #our syntehtic data from 2015, we use them as real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "motivated-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hsize_distributions(df_projected, df_real, hsize_column='hsize', cap=6):\n",
    "    # Cap the hsize values at `cap` for both dataframes\n",
    "    for df in [df_projected, df_real]:\n",
    "        df['hsize_new'] = df[hsize_column].apply(lambda x: x if x < cap else cap)\n",
    "    \n",
    "    # Group by hsize_new and count\n",
    "    combinations_projected = df_projected.groupby(\"hsize_new\").size().reset_index(name=\"Counts_projected\")\n",
    "    combinations_real = df_real.groupby(\"hsize_new\").size().reset_index(name=\"Counts_real\")\n",
    "    \n",
    "    # Merge the grouped results\n",
    "    merged_df = pd.merge(combinations_projected, combinations_real, on=\"hsize_new\", how=\"outer\")\n",
    "    \n",
    "    # Fill missing values with 0 and cast to int\n",
    "    merged_df[\"Counts_projected\"] = merged_df[\"Counts_projected\"].fillna(0).astype(int)\n",
    "    merged_df[\"Counts_real\"] = merged_df[\"Counts_real\"].fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate total counts\n",
    "    total_counts_projected = merged_df[\"Counts_projected\"].sum()\n",
    "    total_counts_real = merged_df[\"Counts_real\"].sum()\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    merged_df[\"Prob_projected\"] = merged_df[\"Counts_projected\"] / total_counts_projected\n",
    "    merged_df[\"Prob_real\"] = merged_df[\"Counts_real\"] / total_counts_real\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statutory-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = compare_hsize_distributions(projected_2010_2015,real_data_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noted-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsize_new</th>\n",
       "      <th>Counts_projected</th>\n",
       "      <th>Counts_real</th>\n",
       "      <th>Prob_projected</th>\n",
       "      <th>Prob_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24037</td>\n",
       "      <td>19372</td>\n",
       "      <td>0.162384</td>\n",
       "      <td>0.154685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43128</td>\n",
       "      <td>40412</td>\n",
       "      <td>0.291354</td>\n",
       "      <td>0.322689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26226</td>\n",
       "      <td>22161</td>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.176955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34540</td>\n",
       "      <td>27756</td>\n",
       "      <td>0.233337</td>\n",
       "      <td>0.221631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14890</td>\n",
       "      <td>10520</td>\n",
       "      <td>0.100590</td>\n",
       "      <td>0.084002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5205</td>\n",
       "      <td>5014</td>\n",
       "      <td>0.035163</td>\n",
       "      <td>0.040037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hsize_new  Counts_projected  Counts_real  Prob_projected  Prob_real\n",
       "0          1             24037        19372        0.162384   0.154685\n",
       "1          2             43128        40412        0.291354   0.322689\n",
       "2          3             26226        22161        0.177172   0.176955\n",
       "3          4             34540        27756        0.233337   0.221631\n",
       "4          5             14890        10520        0.100590   0.084002\n",
       "5          6              5205         5014        0.035163   0.040037"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-electric",
   "metadata": {},
   "source": [
    "### Calculating adiitional observations between projected dataset and new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mysterious-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Since GS cannot delete data but only add, we have to find one positive feasible solution that gives us information on how much observations we should add per household size category. \n",
    "In other words we obtain vector where each element represents counts per each household size category that should be added so we achieve probability distribution of new data. '''\n",
    "def calculate_frequencies(prob_dist_projected, prob_dist_new, counts_projected, counts_new):\n",
    "    \n",
    "\n",
    "    c_total = np.sum(counts_projected)\n",
    "    N = len(prob_dist_new)\n",
    "\n",
    "    M = np.diag(prob_dist_new) @ np.ones(N).reshape(-1,1) @ np.ones(N).reshape(1,-1) - np.eye(N)\n",
    "\n",
    "    eps = 0.01\n",
    "    L_inq = np.eye(N)\n",
    "    r_inq = eps*np.ones(N)\n",
    "\n",
    "    z = cp.Variable(N)\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(1), [L_inq @ z >= r_inq, M @ z == -M @ counts_projected])\n",
    "    prob.solve()\n",
    "\n",
    "    z_array = np.squeeze(np.array(z.value))\n",
    "\n",
    "    print(z_array)\n",
    "\n",
    "    return z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4800.84108586 17030.72568459  6763.64465743  6778.55859897\n",
      "   770.44229936  2259.01689059]\n"
     ]
    }
   ],
   "source": [
    "adding_counts = calculate_frequencies(np.array(merged_df['Prob_projected']), np.array(merged_df['Prob_real']), np.array(merged_df['Counts_projected']), np.array(merged_df['Counts_real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nonprofit-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is double-checking if adding these quantities actually leads to the real probability distribution\n",
    "def compare_adjusted_probs(merged_df, adding_counts):\n",
    "    # Extract projected counts\n",
    "    c = np.array(merged_df['Counts_projected'])\n",
    "\n",
    "    # Compute total\n",
    "    total = np.sum(c) + np.sum(adding_counts)\n",
    "\n",
    "    # Compute adjusted probabilities\n",
    "    adjusted_probs = (c + adding_counts) / total\n",
    "\n",
    "    # Get real probabilities from dataframe\n",
    "    real_probs = np.array(merged_df['Prob_real'])\n",
    "\n",
    "    # Compare with a tolerance (to avoid floating-point issues)\n",
    "    return np.allclose(adjusted_probs, real_probs, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "false-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_equal = compare_adjusted_probs(merged_df, adding_counts)\n",
    "print(is_equal)  # True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-correction",
   "metadata": {},
   "source": [
    "### Gibbs Sampler for adding households \n",
    "\n",
    "\n",
    "#### The reason we chose to add based on household size is because we can modify the number of draws for the Generation method that actually represents the households size distribution\n",
    "\n",
    "#### Thus, we have to perform the following steps:\n",
    "###### 1. Change the number of draws according to the output of calculate_frequencies() function instead of href, also add initial states for each hsize group\n",
    "###### 2. We will obtain the subsample that should be concantenated to the projected one\n",
    "\n",
    "###### 3. We extend the warmup period as much as needed to achieve the convergence, then discard the draws and draw exact desired number of draws from the unique joint distribution (note that in Generation code, the number of draws would inflate until we don't reach the unique joint distribution, so to avoid the post-processing, we changed the MetropolistHasting function)\n",
    "\n",
    "#### The code is in the Generation_subsample_clean.ipynb, results in results/resampling_generation\n",
    "\n",
    "\n",
    "#### Output csv: small sample that should be added to projected sample from this script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-notebook",
   "metadata": {},
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "active-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = pd.read_csv(\"results/resampling_generation/synthetic_individuals.csv\") #loading subsample\n",
    "projection_2010_2015_concat = projected_2010_2015 #loading projected sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "animal-jackson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     4800\n",
       "2    17030\n",
       "3     6762\n",
       "4     6778\n",
       "5      770\n",
       "6     2258\n",
       "Name: hsize, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs['hsize'].value_counts().sort_index() #same as the number of draws given by calculate_frequencies function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "obvious-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_attributes = [\"hid\",\"htype\",\"nbcars_agg\",\"hsize\",\"age_discrete\",\"gender\",\"marital_status\",\"employment\",\"driving_licence\"]\n",
    "projection_2010_2015_concat = projection_2010_2015_concat[working_attributes].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exclusive-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs[\"hid\"] = gs[\"hid\"]+max(projection_2010_2015_concat[\"hid\"]) #so we don't have duplicated ids with the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "returning-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([projection_2010_2015_concat, gs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "composed-appliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>htype</th>\n",
       "      <th>nbcars_agg</th>\n",
       "      <th>hsize</th>\n",
       "      <th>age_discrete</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>driving_licence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186419</th>\n",
       "      <td>113692</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186420</th>\n",
       "      <td>113693</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186421</th>\n",
       "      <td>113694</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186422</th>\n",
       "      <td>113695</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186423</th>\n",
       "      <td>113696</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186424 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hid  htype  nbcars_agg  hsize  age_discrete  gender  \\\n",
       "0            0     10           1      1             6       2   \n",
       "1            1     10           1      1             6       2   \n",
       "2            2     10           0      1             6       2   \n",
       "3            3     10           0      1             6       2   \n",
       "4            7     10           0      1             6       2   \n",
       "...        ...    ...         ...    ...           ...     ...   \n",
       "186419  113692    220           3      6             1       1   \n",
       "186420  113693    220           1      6             5       1   \n",
       "186421  113694    230           1      6             5       1   \n",
       "186422  113695    220           2      6             4       2   \n",
       "186423  113696    220           1      6             1       2   \n",
       "\n",
       "        marital_status  employment  driving_licence  \n",
       "0                    3           4                1  \n",
       "1                    3           1                1  \n",
       "2                    3           4                2  \n",
       "3                    3           4                2  \n",
       "4                    3           4                2  \n",
       "...                ...         ...              ...  \n",
       "186419               1           5                2  \n",
       "186420               2           1                1  \n",
       "186421               2           1                1  \n",
       "186422               2           1                1  \n",
       "186423               1           5                2  \n",
       "\n",
       "[186424 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset #data size inflated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "seasonal-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"results/resampled_2015_GS.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "automotive-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsize_new</th>\n",
       "      <th>Counts_projected</th>\n",
       "      <th>Counts_real</th>\n",
       "      <th>Prob_projected</th>\n",
       "      <th>Prob_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28837</td>\n",
       "      <td>19372</td>\n",
       "      <td>0.154685</td>\n",
       "      <td>0.154685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60158</td>\n",
       "      <td>40412</td>\n",
       "      <td>0.322695</td>\n",
       "      <td>0.322689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32988</td>\n",
       "      <td>22161</td>\n",
       "      <td>0.176951</td>\n",
       "      <td>0.176955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41318</td>\n",
       "      <td>27756</td>\n",
       "      <td>0.221635</td>\n",
       "      <td>0.221631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15660</td>\n",
       "      <td>10520</td>\n",
       "      <td>0.084002</td>\n",
       "      <td>0.084002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7463</td>\n",
       "      <td>5014</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.040037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hsize_new  Counts_projected  Counts_real  Prob_projected  Prob_real\n",
       "0          1             28837        19372        0.154685   0.154685\n",
       "1          2             60158        40412        0.322695   0.322689\n",
       "2          3             32988        22161        0.176951   0.176955\n",
       "3          4             41318        27756        0.221635   0.221631\n",
       "4          5             15660        10520        0.084002   0.084002\n",
       "5          6              7463         5014        0.040032   0.040037"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_hsize_distributions(final_dataset, real_data_2015) #the probabilities the same, although the counts are different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-integrity",
   "metadata": {},
   "source": [
    "### Uniformly deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accepted-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excess population to delete: 38398\n",
      "Final Adjusted Count: 148026\n",
      "Final sample size matches original projected: True\n",
      "\n",
      "--- Comparison Between Final and Real Probabilities ---\n",
      "Household Size 1: Real Prob = 0.1547, Final Prob = 0.1547, Diff = 0.0000\n",
      "Household Size 2: Real Prob = 0.3227, Final Prob = 0.3227, Diff = 0.0000\n",
      "Household Size 3: Real Prob = 0.1770, Final Prob = 0.1769, Diff = 0.0000\n",
      "Household Size 4: Real Prob = 0.2216, Final Prob = 0.2216, Diff = 0.0000\n",
      "Household Size 5: Real Prob = 0.0840, Final Prob = 0.0840, Diff = 0.0000\n",
      "Household Size 6: Real Prob = 0.0400, Final Prob = 0.0328, Diff = 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total excess population\n",
    "projected_total = len(projected_2010_2015)\n",
    "excess_to_delete = len(final_dataset) - projected_total\n",
    "\n",
    "# Check if excess_to_delete is a positive number\n",
    "if excess_to_delete > 0:\n",
    "    print(f\"Excess population to delete: {excess_to_delete}\")\n",
    "else:\n",
    "    print(\"No excess population to delete. Final sample already matches projected size.\")\n",
    "\n",
    "# Get the household size counts from the augmented dataset\n",
    "augmented_counts = final_dataset['hsize'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the proportions for each household size category\n",
    "delete_share = augmented_counts / augmented_counts.sum()\n",
    "\n",
    "# Calculate how many observations to remove for each household size category\n",
    "to_delete = np.round(delete_share * excess_to_delete).astype(int)\n",
    "\n",
    "# Step 5: Perform deletion in final_dataset\n",
    "final_dataset_adjusted = []\n",
    "\n",
    "# Iterate over each household size category\n",
    "for size, delete_count in to_delete.items():\n",
    "    category_data = final_dataset[final_dataset['hsize'] == size]\n",
    "    \n",
    "    # If we need to delete any rows, sample them randomly and remove\n",
    "    if delete_count > 0:\n",
    "        indices_to_delete = category_data.sample(n=delete_count, random_state=42).index\n",
    "        category_data = category_data.drop(indices_to_delete)\n",
    "    \n",
    "    final_dataset_adjusted.append(category_data)\n",
    "\n",
    "# Concatenate the final adjusted dataset\n",
    "final_dataset_adjusted = pd.concat(final_dataset_adjusted)\n",
    "\n",
    "# Check if the final size matches the original projected size\n",
    "final_size = len(final_dataset_adjusted)\n",
    "print(f\"Final Adjusted Count: {final_size}\")\n",
    "print(f\"Final sample size matches original projected: {final_size == projected_total}\")\n",
    "\n",
    "# Step 6: Compare final probabilities with real probabilities\n",
    "final_counts = final_dataset_adjusted['hsize'].value_counts().sort_index()\n",
    "final_probs = final_counts / final_counts.sum()\n",
    "\n",
    "# Real probabilities (you should have these from the real dataset)\n",
    "real_counts = np.array(real_data_2015.hsize_new.value_counts().sort_index())  # Example probabilities\n",
    "real_total = real_counts.sum()\n",
    "real_probs = real_counts / real_total\n",
    "\n",
    "print(\"\\n--- Comparison Between Final and Real Probabilities ---\")\n",
    "for size, final_prob, real_prob in zip(range(1, 7), final_probs, real_probs):\n",
    "    print(f\"Household Size {size}: Real Prob = {real_prob:.4f}, Final Prob = {final_prob:.4f}, Diff = {abs(real_prob - final_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-paragraph",
   "metadata": {},
   "source": [
    "### Example from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "owned-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Projected Sample ---\n",
      "Household Size 1: Count = 23287, Probability = 0.1590\n",
      "Household Size 2: Count = 43760, Probability = 0.2987\n",
      "Household Size 3: Count = 26357, Probability = 0.1799\n",
      "Household Size 4: Count = 33620, Probability = 0.2295\n",
      "Household Size 5: Count = 14195, Probability = 0.0969\n",
      "Household Size 6: Count = 5282, Probability = 0.0361\n",
      "Total Projected Count: 146501\n",
      "\n",
      "--- Step 2: Real Sample ---\n",
      "Household Size 1: Count = 19373, Probability = 0.1542\n",
      "Household Size 2: Count = 40286, Probability = 0.3206\n",
      "Household Size 3: Count = 21786, Probability = 0.1734\n",
      "Household Size 4: Count = 28237, Probability = 0.2247\n",
      "Household Size 5: Count = 10320, Probability = 0.0821\n",
      "Household Size 6: Count = 5649, Probability = 0.0450\n",
      "Total Real Count: 125651\n",
      "\n",
      "--- Step 3: Augmentation ---\n",
      "Household Size 1: Projected = 23287, Added = 3658, Augmented = 26945, Aug. Prob = 0.1542\n",
      "Household Size 2: Projected = 43760, Added = 12272, Augmented = 56032, Aug. Prob = 0.3206\n",
      "Household Size 3: Projected = 26357, Added = 3944, Augmented = 30301, Aug. Prob = 0.1734\n",
      "Household Size 4: Projected = 33620, Added = 5653, Augmented = 39273, Aug. Prob = 0.2247\n",
      "Household Size 5: Projected = 14195, Added = 159, Augmented = 14354, Aug. Prob = 0.0821\n",
      "Household Size 6: Projected = 5282, Added = 2575, Augmented = 7857, Aug. Prob = 0.0450\n",
      "Total Augmented Count: 174762\n",
      "Difference in count from projected: 28261\n",
      "Difference in count from real: 49111\n",
      "\n",
      "--- Step 4: Deletion and Final Sample ---\n",
      "Household Size 1: Final Count = 22588, Final Prob = 0.1542\n",
      "Household Size 2: Final Count = 46971, Final Prob = 0.3206\n",
      "Household Size 3: Final Count = 25401, Final Prob = 0.1734\n",
      "Household Size 4: Final Count = 32922, Final Prob = 0.2247\n",
      "Household Size 5: Final Count = 12033, Final Prob = 0.0821\n",
      "Household Size 6: Final Count = 6586, Final Prob = 0.0450\n",
      "Total Final Count: 146501\n",
      "Final sample size matches original projected: True\n",
      "\n",
      "--- Step 5: Comparison Between Final and Real Probabilities ---\n",
      "Household Size 1: Real Prob = 0.1542, Final Prob = 0.1542, Diff = 0.0000\n",
      "Household Size 2: Real Prob = 0.3206, Final Prob = 0.3206, Diff = 0.0000\n",
      "Household Size 3: Real Prob = 0.1734, Final Prob = 0.1734, Diff = 0.0000\n",
      "Household Size 4: Real Prob = 0.2247, Final Prob = 0.2247, Diff = 0.0000\n",
      "Household Size 5: Real Prob = 0.0821, Final Prob = 0.0821, Diff = 0.0000\n",
      "Household Size 6: Real Prob = 0.0450, Final Prob = 0.0450, Diff = 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "# Function to compute added frequencies using constrained optimization\n",
    "def calculate_frequencies(prob_dist_projected, prob_dist_new, counts_projected, counts_new):\n",
    "    c_total = np.sum(counts_projected)\n",
    "    N = len(prob_dist_new)\n",
    "\n",
    "    M = np.diag(prob_dist_new) @ np.ones(N).reshape(-1,1) @ np.ones(N).reshape(1,-1) - np.eye(N)\n",
    "\n",
    "    eps = 0.01\n",
    "    L_inq = np.eye(N)\n",
    "    r_inq = eps * np.ones(N)\n",
    "\n",
    "    z = cp.Variable(N)\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(1), [L_inq @ z >= r_inq, M @ z == -M @ counts_projected])\n",
    "    prob.solve()\n",
    "\n",
    "    z_array = np.squeeze(np.array(z.value))\n",
    "    return np.round(z_array).astype(int)\n",
    "\n",
    "# Inputs: projected and real counts\n",
    "projected_counts = np.array([23287, 43760, 26357, 33620, 14195, 5282])\n",
    "real_counts = np.array([19373, 40286, 21786, 28237, 10320, 5649])\n",
    "household_sizes = np.arange(1, 7)\n",
    "\n",
    "### STEP 1: Print projected sample\n",
    "projected_total = projected_counts.sum()\n",
    "projected_probs = projected_counts / projected_total\n",
    "print(\"\\n--- Step 1: Projected Sample ---\")\n",
    "for size, count, prob in zip(household_sizes, projected_counts, projected_probs):\n",
    "    print(f\"Household Size {size}: Count = {count}, Probability = {prob:.4f}\")\n",
    "print(f\"Total Projected Count: {projected_total}\")\n",
    "\n",
    "### STEP 2: Print real sample\n",
    "real_total = real_counts.sum()\n",
    "real_probs = real_counts / real_total\n",
    "print(\"\\n--- Step 2: Real Sample ---\")\n",
    "for size, count, prob in zip(household_sizes, real_counts, real_probs):\n",
    "    print(f\"Household Size {size}: Count = {count}, Probability = {prob:.4f}\")\n",
    "print(f\"Total Real Count: {real_total}\")\n",
    "\n",
    "### STEP 3: Add frequencies to match real probabilities\n",
    "added_counts = calculate_frequencies(projected_probs, real_probs, projected_counts, real_counts)\n",
    "augmented_counts = projected_counts + added_counts\n",
    "augmented_total = augmented_counts.sum()\n",
    "augmented_probs = augmented_counts / augmented_total\n",
    "\n",
    "print(\"\\n--- Step 3: Augmentation ---\")\n",
    "for size, proj, add, aug, prob in zip(household_sizes, projected_counts, added_counts, augmented_counts, augmented_probs):\n",
    "    print(f\"Household Size {size}: Projected = {proj}, Added = {add}, Augmented = {aug}, Aug. Prob = {prob:.4f}\")\n",
    "print(f\"Total Augmented Count: {augmented_total}\")\n",
    "print(f\"Difference in count from projected: {augmented_total - projected_total}\")\n",
    "print(f\"Difference in count from real: {augmented_total - real_total}\")\n",
    "\n",
    "### STEP 4: Delete to restore original projected total size\n",
    "excess_to_delete = augmented_total - projected_total\n",
    "delete_share = augmented_counts / augmented_total\n",
    "to_delete = np.round(delete_share * excess_to_delete).astype(int)\n",
    "final_counts = augmented_counts - to_delete\n",
    "final_total = final_counts.sum()\n",
    "final_probs = final_counts / final_total\n",
    "\n",
    "print(\"\\n--- Step 4: Deletion and Final Sample ---\")\n",
    "for size, final_count, final_prob in zip(household_sizes, final_counts, final_probs):\n",
    "    print(f\"Household Size {size}: Final Count = {final_count}, Final Prob = {final_prob:.4f}\")\n",
    "print(f\"Total Final Count: {final_total}\")\n",
    "print(f\"Final sample size matches original projected: {final_total == projected_total}\")\n",
    "\n",
    "### STEP 5: Compare final probabilities with real\n",
    "print(\"\\n--- Step 5: Comparison Between Final and Real Probabilities ---\")\n",
    "for size, real_p, final_p in zip(household_sizes, real_probs, final_probs):\n",
    "    print(f\"Household Size {size}: Real Prob = {real_p:.4f}, Final Prob = {final_p:.4f}, Diff = {abs(real_p - final_p):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
